{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Course Project\n",
    "\n",
    "* Muhammet Emin Yüce\n",
    "* Recep Oğuzhan Çetin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT change this\n",
    "KERNEL_SIZE = 3\n",
    "# change path to Dataset directory which contains images\n",
    "def ImRead(PICTURE_NUM):\n",
    "    path = \"C:/Users/ycema/Desktop/Machine Learning Project/ProjectTestImages\"\n",
    "\n",
    "    # Path addition\n",
    "    if(PICTURE_NUM < 10):\n",
    "        source_picture_name = \"/p00\"+ str(PICTURE_NUM)+ \", a_source.png\"\n",
    "        target_name = \"/p00\"+ str(PICTURE_NUM)+ \", b_target.png\"\n",
    "        ground_truth_name = \"/p00\"+ str(PICTURE_NUM)+ \", c_groundtruth.png\"\n",
    "    else:\n",
    "        source_picture_name = \"/p0\"+ str(PICTURE_NUM)+ \", a_source.png\"\n",
    "        target_name = \"/p0\"+ str(PICTURE_NUM)+ \", b_target.png\"\n",
    "        ground_truth_name = \"/p0\"+ str(PICTURE_NUM)+ \", c_groundtruth.png\"\n",
    "\n",
    "    # Image read for Source which is y_train and it's grayscale conversion which is x_train, \n",
    "    # Target image which is X_test, Groundtruth which is y_test\n",
    "    src_img = cv2.imread(path + source_picture_name) #y_train\n",
    "    gray_img = cv2.cvtColor(src_img, cv2.COLOR_BGR2GRAY) # X_train\n",
    "    target_img = cv2.imread(path + target_name,cv2.IMREAD_GRAYSCALE) #x_test\n",
    "    groundtruth_img = cv2.imread(path + ground_truth_name)\n",
    "\n",
    "    target_dim = target_img.shape\n",
    "    return src_img, gray_img, target_img, groundtruth_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sift Feature Extraction\n",
    "def siftFeatureExt(img):\n",
    "    # This Function requires pip install opencv-contrib-python for 4.5.1 , \n",
    "    # in case you don't have it, run pip uninstall opencv then run pip install opencv-contrib-python\n",
    "    \n",
    "    # This code is an implementation of \n",
    "    # https://medium.com/machine-learning-world/feature-extraction-and-similar-image-search-with-opencv-for-newbies-3c59796bf774\n",
    "    sift = cv2.xfeatures2d.SIFT_create(edgeThreshold = 10)\n",
    "    # For Keypoints\n",
    "    kp = sift.detect(gray_img,None)\n",
    "    # For Descriptors\n",
    "    kps, dsc = sift.compute(gray_img, kp)\n",
    "\n",
    "    # Making it sklearn compatible\n",
    "    dsc = dsc.flatten()\n",
    "    needed_size = img.shape[0]* img.shape[1]\n",
    "    if dsc.size < needed_size:\n",
    "        dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    else:\n",
    "        return dsc[:needed_size]\n",
    "    return dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "# This function creates all the kernel then convolves the actual input with them\n",
    "# Which Results in features for the Model \n",
    "def ExtractFeatures(img):\n",
    "    kernel_dim = (KERNEL_SIZE,KERNEL_SIZE)\n",
    "    \n",
    "    kernels = []\n",
    "    \n",
    "#     Laplacian kernel\n",
    "#     Laplacian_kernel = np.array([[0,1,0],\n",
    "#                                   [1,-4,1],\n",
    "#                                   [0,1,1]])\n",
    "#     Sobeloperator_kernel = np.array([[-1,0,1],\n",
    "#                                  [-2,0,2],\n",
    "#                                  [-1,0,1]])\n",
    "#     Sobeloperator_kernel2 = np.array([[1,2,1],\n",
    "#                                  [0,0,0],\n",
    "#                                  [-1,-2,-1]])\n",
    "#     kernels.append(Laplacian_kernel)#[1,0,0]\n",
    "                                    #[0,0,0]\n",
    "                                    #[0,0,0]\n",
    "#     kernels.append(Sobeloperator_kernel)\n",
    "#     kernels.append(Sobeloperator_kernel2)\n",
    "\n",
    "    # 8 Neighbor Filters\n",
    "    for i in range(KERNEL_SIZE):\n",
    "        for j in range(KERNEL_SIZE):\n",
    "            kernel = np.zeros(kernel_dim)\n",
    "            kernel[i,j] = 1\n",
    "            kernels.append(kernel)\n",
    "        \n",
    "    img_ft = np.float32(img)\n",
    "    # Corner Harris Filter\n",
    "    corner_out = cv2.cornerHarris(img_ft,2,3,0.04).flatten()\n",
    "    \n",
    "    \n",
    "    # Generating the features by 2d convolution\n",
    "    features = []\n",
    "    features.append(img.flatten())\n",
    "    for i in kernels:\n",
    "        features.append(np.asarray(convolve2d(img,i, \"same\")).flatten())\n",
    "    features.append(corner_out)\n",
    "    features.append(siftFeatureExt(img))\n",
    "    \n",
    "    # Transpose the features to fit the sklearn input format\n",
    "    features = np.transpose(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "\n",
    "def fitModel(X):\n",
    "    start = time.time()\n",
    "    \n",
    "    # 3 Models for r,g,b channels\n",
    "#     reg_b = DecisionTreeRegressor()\n",
    "#     reg_g = DecisionTreeRegressor()\n",
    "#     reg_r = DecisionTreeRegressor()\n",
    "    \n",
    "    # These Methods below grants better results but they take mush more time \n",
    "    # for 30 images test case they are Commented out\n",
    "    \n",
    "#     reg_b = RandomForestRegressor(n_estimators = 3)\n",
    "#     reg_g = RandomForestRegressor(n_estimators = 3)\n",
    "#     reg_r = RandomForestRegressor(n_estimators = 3)\n",
    "    \n",
    "    # Pipeline method LinearRegression for getting most important features, selected 15 because its fast and efficient model\n",
    "    # Decision tree for the pixel value regression\n",
    "    reg_b = Pipeline([\n",
    "      ('feature_selection', SelectFromModel(LinearRegression(),max_features = 30)),\n",
    "      ('Regression', RandomForestRegressor(n_estimators = 30,n_jobs = -1, warm_start = True))\n",
    "    ])\n",
    "    reg_g = Pipeline([\n",
    "      ('feature_selection', SelectFromModel(LinearRegression(),max_features = 30)),\n",
    "      ('Regression', RandomForestRegressor(n_estimators = 30,n_jobs = -1, warm_start = True))\n",
    "    ])\n",
    "    reg_r = Pipeline([\n",
    "      ('feature_selection', SelectFromModel(LinearRegression(),max_features = 30)),\n",
    "      ('Regression', RandomForestRegressor(n_estimators = 30,n_jobs = -1, warm_start = True))\n",
    "    ])\n",
    "\n",
    "    reg_b.fit(X, b_y)\n",
    "    reg_g.fit(X, g_y)\n",
    "    reg_r.fit(X, r_y)\n",
    "\n",
    "    \n",
    "    end2 = time.time()\n",
    "    print(\"Train time:{0:.2f} sec.\".format(end2-start))\n",
    "    return reg_b,reg_g,reg_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictColorizedImage(X_test,reg_b,reg_g,reg_r):\n",
    "\n",
    "    X_test = polynomial_features.transform(X_test)\n",
    "    b_yhat = reg_b.predict(X_test).astype(np.uint8).reshape(target_dim[0],target_dim[1])\n",
    "    g_yhat = reg_g.predict(X_test).astype(np.uint8).reshape(target_dim[0],target_dim[1])\n",
    "    r_yhat = reg_r.predict(X_test).astype(np.uint8).reshape(target_dim[0],target_dim[1])\n",
    "    #print(b_yhat.shape,g_yhat.shape,r_yhat.shape)\n",
    "    # Merge 3 regressors predictions\n",
    "    yhat = cv2.merge((b_yhat,g_yhat,r_yhat))\n",
    "    #print(yhat.shape)\n",
    "    yhat = yhat.astype(np.uint8)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:5.79 sec.\n",
      "Mae for Image 1 is 18.03\n",
      "\n",
      "Train time:12.00 sec.\n",
      "Mae for Image 2 is 17.33\n",
      "\n",
      "Train time:11.25 sec.\n",
      "Mae for Image 3 is 15.42\n",
      "\n",
      "Train time:7.03 sec.\n",
      "Mae for Image 4 is 7.34\n",
      "\n",
      "Train time:12.13 sec.\n",
      "Mae for Image 5 is 9.05\n",
      "\n",
      "Train time:13.67 sec.\n",
      "Mae for Image 6 is 21.13\n",
      "\n",
      "Train time:11.69 sec.\n",
      "Mae for Image 7 is 16.67\n",
      "\n",
      "Train time:6.39 sec.\n",
      "Mae for Image 8 is 12.33\n",
      "\n",
      "Train time:8.05 sec.\n",
      "Mae for Image 9 is 16.36\n",
      "\n",
      "Train time:6.77 sec.\n",
      "Mae for Image 10 is 19.34\n",
      "\n",
      "Train time:10.20 sec.\n",
      "Mae for Image 11 is 11.81\n",
      "\n",
      "Train time:7.14 sec.\n",
      "Mae for Image 12 is 21.57\n",
      "\n",
      "Train time:1.51 sec.\n",
      "Mae for Image 13 is 33.41\n",
      "\n",
      "Train time:24.95 sec.\n",
      "Mae for Image 14 is 12.62\n",
      "\n",
      "Train time:17.33 sec.\n",
      "Mae for Image 15 is 27.60\n",
      "\n",
      "Train time:1.86 sec.\n",
      "Mae for Image 16 is 25.80\n",
      "\n",
      "Train time:4.93 sec.\n",
      "Mae for Image 17 is 15.43\n",
      "\n",
      "Train time:17.36 sec.\n",
      "Mae for Image 18 is 14.38\n",
      "\n",
      "Train time:13.24 sec.\n",
      "Mae for Image 19 is 16.56\n",
      "\n",
      "Train time:4.72 sec.\n",
      "Mae for Image 20 is 15.33\n",
      "\n",
      "Train time:6.91 sec.\n",
      "Mae for Image 21 is 17.35\n",
      "\n",
      "Train time:5.01 sec.\n",
      "Mae for Image 22 is 14.88\n",
      "\n",
      "Train time:21.20 sec.\n",
      "Mae for Image 23 is 21.57\n",
      "\n",
      "Train time:12.70 sec.\n",
      "Mae for Image 24 is 12.08\n",
      "\n",
      "Train time:33.36 sec.\n",
      "Mae for Image 25 is 7.57\n",
      "\n",
      "Train time:11.49 sec.\n",
      "Mae for Image 26 is 15.37\n",
      "\n",
      "Train time:14.09 sec.\n",
      "Mae for Image 27 is 12.66\n",
      "\n",
      "Train time:7.13 sec.\n",
      "Mae for Image 28 is 7.80\n",
      "\n",
      "Train time:27.93 sec.\n",
      "Mae for Image 29 is 9.50\n",
      "\n",
      "Train time:8.69 sec.\n",
      "Mae for Image 30 is 4.41\n",
      "\n",
      "Train time:5.48 sec.\n",
      "Mae for Image 31 is 6.94\n",
      "\n",
      "Train time:7.35 sec.\n",
      "Mae for Image 32 is 6.62\n",
      "\n",
      "Train time:13.55 sec.\n",
      "Mae for Image 33 is 15.20\n",
      "\n",
      "Train time:11.09 sec.\n",
      "Mae for Image 34 is 12.86\n",
      "\n",
      "Train time:13.24 sec.\n",
      "Mae for Image 35 is 9.53\n",
      "\n",
      "Train time:12.73 sec.\n",
      "Mae for Image 36 is 4.36\n",
      "\n",
      "Train time:13.61 sec.\n",
      "Mae for Image 37 is 10.96\n",
      "\n",
      "Train time:12.92 sec.\n",
      "Mae for Image 38 is 18.64\n",
      "\n",
      "Train time:10.19 sec.\n",
      "Mae for Image 39 is 10.37\n",
      "\n",
      "Train time:7.42 sec.\n",
      "Mae for Image 40 is 10.58\n",
      "\n",
      "Train time:8.07 sec.\n",
      "Mae for Image 41 is 11.39\n",
      "\n",
      "Train time:21.25 sec.\n",
      "Mae for Image 42 is 9.89\n",
      "\n",
      "Train time:16.45 sec.\n",
      "Mae for Image 43 is 31.20\n",
      "\n",
      "Train time:2.11 sec.\n",
      "Mae for Image 44 is 15.98\n",
      "\n",
      "Train time:16.71 sec.\n",
      "Mae for Image 45 is 9.87\n",
      "\n",
      "Train time:11.12 sec.\n",
      "Mae for Image 46 is 11.79\n",
      "\n",
      "Train time:4.34 sec.\n",
      "Mae for Image 47 is 4.16\n",
      "\n",
      "Train time:7.64 sec.\n",
      "Mae for Image 48 is 12.97\n",
      "\n",
      "Train time:30.53 sec.\n",
      "Mae for Image 49 is 11.49\n",
      "\n",
      "Train time:3.52 sec.\n",
      "Mae for Image 50 is 64.93\n",
      "\n",
      "Total Train time:633.24\n",
      "END\n",
      "Average MAE: 15.209709849293713\n"
     ]
    }
   ],
   "source": [
    "# Main Code\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "minImageIndex = 1\n",
    "maxImageIndex = 50\n",
    "\n",
    "f = open(\"ProjectTestImagesResults.txt\", \"w\")\n",
    "\n",
    "start = time.time()\n",
    "total_mae = 0\n",
    "for i in range(minImageIndex,maxImageIndex + 1):\n",
    "    # Image reading\n",
    "    src_img, gray_img, target_img, groundtruth_img = ImRead(i)\n",
    "    \n",
    "    #Split the y_train so we can make 3 regressors\n",
    "    b_y, g_y, r_y = cv2.split(src_img)\n",
    "    b_y = np.asarray(b_y).flatten()\n",
    "    g_y = np.asarray(g_y).flatten()\n",
    "    r_y = np.asarray(r_y).flatten()\n",
    "    \n",
    "    # Extract Features for model input\n",
    "    X = ExtractFeatures(gray_img)\n",
    "    \n",
    "    # Polynomial Features helps to get better output but requires more time\n",
    "    # Commented out for 30 image test case\n",
    "    # If you want to test with polynomial Features \n",
    "    # uncomment this area with the part that is in functionpredictColorizedImage\n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree = 2)\n",
    "    X = polynomial_features.fit_transform(X)\n",
    "    r_b, r_g , r_r = fitModel(X)\n",
    "\n",
    "    # Extract Features for test data input\n",
    "    target_dim = target_img.shape\n",
    "    X_test = ExtractFeatures(target_img)\n",
    "    yhat = predictColorizedImage(X_test,r_b,r_g,r_r)\n",
    "    \n",
    "    mae = mean_absolute_error(np.array(groundtruth_img).flatten().astype(int),np.array(yhat).flatten().astype(int))\n",
    "    print('Mae for Image '+str(i)+' is {0:.2f}'.format(mae))\n",
    "    print()\n",
    "    total_mae += mae\n",
    "    #Show the images\n",
    "#     cv2.imshow(\"Predicted img:\"+str(i) , yhat)\n",
    "    cv2.imwrite(str(i)+\".jpg\", yhat) \n",
    "    f.write(str(mae))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "f.write(\"\\n\")\n",
    "f.write(str(total_mae/maxImageIndex))\n",
    "f.close()\n",
    "end2 = time.time()\n",
    "# Wait for this print line executes before opening any image window or kernel dies thanks to opencv\n",
    "print(\"Total Train time:{0:.2f}\".format(end2-start))\n",
    "print('END')\n",
    "print('Average MAE:',total_mae/maxImageIndex)\n",
    "# cv2.waitKey(0)\n",
    "  \n",
    "#closing all open windows  \n",
    "# cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
